# -*- coding: utf-8 -*-
"""sloan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13kKuPVRcSniMnkwbZNOc90Yz-QrSipq8

# read in, examine
"""

import pandas as pd

!wget https://github.com/arewelearningyet/dashtemplate/blob/master/assets/Skyserver_12_30_2019_4_49_58_PM.csv.zip?raw=true

!unzip Skyserver_12_30_2019_4_49_58_PM.csv.zip\?raw\=true

df = pd.read_csv('Skyserver_12_30_2019 4_49_58 PM.csv')

df_alpha = df.copy() # creating backup copy

df.head().T

pd.options.display.float_format = '{:.2f}'.format

df.describe().T

df.objid.nunique()

df.specobjid.nunique()

df = df.drop(columns='specobjid')

df.describe(exclude='number')

df.shape

"""# create binary classes from multiclass feature 'class'"""

df_alpha['class'].unique()

class_distribution = df_alpha['class'].value_counts(normalize=True).reset_index()

class_distribution.iloc[1][0]

class_distribution.iloc[1][1]

class_distribution.iloc[0]

"""# TODO: put naive baseline in here - insights about multiclass classification, 'difficulty'"""

import plotly.graph_objects as go
colors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen']

fig = go.Figure(data=[go.Pie(labels=[class_distribution.iloc[0][0],
                                     class_distribution.iloc[1][0],
                                     class_distribution.iloc[2][0]],
                             values=[class_distribution.iloc[0][1], 
                                     class_distribution.iloc[1][1],
                                     class_distribution.iloc[2][1]])])
fig.update_traces(hoverinfo='label+percent', textinfo='text+label+percent', textfont_size=20,
                  marker=dict(colors=colors, line=dict(color='#000000', width=2,)))
fig.show()



import dash_core_components as dcc
import matplotlib.pyplot as plt
from plotly.tools import mpl_to_plotly
layout = dcc.Graph(id='class_pie', figure=fig)

df['galaxy']=df['class']=='GALAXY'
df['star'] = df['class']=='STAR'
df['quasar'] = df['class']=='QSO'

df=df.drop(columns='class')

df.quasar.value_counts()

"""# train test split"""

from sklearn.model_selection import train_test_split

trainalpha, test = train_test_split(df)

train, val = train_test_split(trainalpha)

"""# set target"""

target = 'quasar'

xtrain=train.drop(columns=['quasar', 'galaxy', 'star'])
ytrain=train[target]
xval=val.drop(columns=['quasar', 'galaxy', 'star'])
yval=val[target]
xtest=test.drop(columns=['quasar', 'galaxy', 'star'])
ytest=test[target]

"""# import viz libraries"""

import matplotlib.pyplot as plt

# dash stuff
from plotly.tools import mpl_to_plotly

"""# import modeling libraries"""

# preprocesing

# pipeline

"""# linear model"""

from sklearn.linear_model import LogisticRegressionCV#, LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

#model = LogisticRegression().fit(xtrain, ytrain)
pipeline = make_pipeline(
    StandardScaler(),
    LogisticRegressionCV()
)
pipeline.fit(xtrain, ytrain)
print('Validation Accuracy: ', pipeline.score(xval, yval))

lr = pipeline.named_steps['logisticregressioncv']
importances = pd.Series(lr.coef_[0], xtrain.columns)
n = 20
plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
importances.sort_values()[-n:].plot.barh(color='grey');

# port figure to plotly
lr = pipeline.named_steps['logisticregressioncv']
importances = pd.Series(lr.coef_[0], xtrain.columns)
n = 20
logregimports = plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
importances.sort_values()[-n:].plot.barh(color='grey');
pltyfig = mpl_to_plotly(logregimports)

pltyfig.show()

dump(pipeline, 'isquasarrf.joblib', compress=True)

"""# ensemble model"""

# one hot encoding with random forest
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# print('Baseline Accuracy: ', train['quasar'].value_counts(normalize=True)[0])
# 
# pipeline=make_pipeline(
#     RandomForestClassifier(random_state=0, n_jobs=-1)
# )
# # fit on train, score on val
# pipeline.fit(xtrain, ytrain)
# print('Validation Accuracy: ', pipeline.score(xval, yval))
# 
# rf = pipeline.named_steps['randomforestclassifier']
# importances = pd.Series(rf.feature_importances_, xtrain.columns)
# n = 20
# plt.figure(figsize=(10,n/2))
# plt.title(f'Top {n} features')
# importances.sort_values()[-n:].plot.barh(color='grey');

"""# predict galaxy"""

target = 'galaxy'

xtrain=train.drop(columns=['quasar', 'galaxy', 'star'])
ytrain=train[target]
xval=val.drop(columns=['quasar', 'galaxy', 'star'])
yval=val[target]
xtest=test.drop(columns=['quasar', 'galaxy', 'star'])
ytest=test[target]

print('Baseline Accuracy: ', train['galaxy'].value_counts(normalize=True)[0])

pipeline=make_pipeline(
    RandomForestClassifier(random_state=0, n_jobs=-1)
)
# fit on train, score on val
pipeline.fit(xtrain, ytrain)
print('Validation Accuracy: ', pipeline.score(xval, yval))

rf = pipeline.named_steps['randomforestclassifier']
importances = pd.Series(rf.feature_importances_, xtrain.columns)
n = 20
plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
importances.sort_values()[-n:].plot.barh(color='grey');

#pkl
from joblib import dump

dump(pipeline, 'isgalaxyrf.joblib', compress=True)

# get versions
import joblib
import pandas
import sklearn
import matplotlib
import plotly

print(f'joblib=={joblib.__version__}')
print(f'pandas=={pandas.__version__}')
print(f'matplotlib=={matplotlib.__version__}')
print(f'plotly=={plotly.__version__}')
print(f'sklearn=={sklearn.__version__}')

"""# predict star"""

target = 'star'

xtrain=train.drop(columns=['quasar', 'galaxy', 'star'])
ytrain=train[target]
xval=val.drop(columns=['quasar', 'galaxy', 'star'])
yval=val[target]
xtest=test.drop(columns=['quasar', 'galaxy', 'star'])
ytest=test[target]

print('Baseline Accuracy: ', train['star'].value_counts(normalize=True)[0])

pipeline=make_pipeline(
    SimpleImputer(strategy='median'),
    RandomForestClassifier(random_state=0, n_jobs=-1)
)
# fit on train, score on val
pipeline.fit(xtrain, ytrain)
print('Validation Accuracy: ', pipeline.score(xval, yval))

dump(pipeline, 'isstarrf.joblib', compress=True)

rf = pipeline.named_steps['randomforestclassifier']
importances = pd.Series(rf.feature_importances_, xtrain.columns)
n = 20
plt.figure(figsize=(10,n/2))
plt.title(f'Top {n} features')
importances.sort_values()[-n:].plot.barh(color='grey');

"""# viz"""

plt.scatter(df_alpha['class'], df_alpha['redshift'])

